name: Daily Collage Pipeline

on:
  schedule:
    - cron: "20 */6 * * *" # GDELT updates every 15 minutes, so run at 20 past every 6th hour
  workflow_dispatch:
    inputs:
      country:
        description: "Country name or FIPS code (e.g., 'sweden', 'us')"
        required: false
        default: "sweden"
      city:
        description: "City/region label for storage"
        required: false
        default: "stockholm"
      date:
        description: "Date (UTC) in YYYY-MM-DD"
        required: false
        default: ""
      window:
        description: "6h window (UTC) in 'HH-HH' format (00-06, 06-12, 12-18, 18-24)"
        required: false
        default: ""

env:
  COUNTRY: ${{ inputs.country || 'sweden' }}
  CITY: ${{ inputs.city || 'stockholm' }}
  CLASSIFIER_ENDPOINT: https://terahidro2003--daily-collage-classifier-api-predict.modal.run

defaults:
  run:
    working-directory: backend

jobs:
  fetch-headlines:
    runs-on: ubuntu-latest
    outputs:
      # Map step outputs to job outputs
      date: ${{ steps.window.outputs.date }}
      window: ${{ steps.window.outputs.window }}
    env:
      HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
      HOPSWORKS_PROJECT: ${{ secrets.HOPSWORKS_PROJECT || vars.HOPSWORKS_PROJECT }}
      HOPSWORKS_HOST: ${{ secrets.HOPSWORKS_HOST || vars.HOPSWORKS_HOST }}
      STORAGE_BACKEND: ${{ vars.STORAGE_BACKEND || 'local' }}
      STORAGE_BUCKET_NAME: ${{ vars.STORAGE_BUCKET_NAME || 'vibe-images' }}
      ASSETS_DIR: ${{ vars.ASSETS_DIR || './assets' }}
    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 1
          sparse-checkout: |
            backend
            .github
      - name: Set up uv
        uses: astral-sh/setup-uv@v7
        with:
          python-version: "3.13"
          enable-cache: true
      - name: Install dependencies
        run: uv sync --frozen
      - name: Compute date & window
        id: window
        env:
          # Explicitly map inputs to env vars for the Python script
          # If triggered by schedule, these will be empty strings
          INPUT_DATE: ${{ inputs.date }}
          INPUT_WINDOW: ${{ inputs.window }}
        run: |
          uv run python - <<'PY'
          import os
          from datetime import datetime
          
          # Read env vars mapped from inputs
          in_date = os.environ.get('INPUT_DATE', '').strip()
          in_window = os.environ.get('INPUT_WINDOW', '').strip()
          
          if in_date and in_window:
              date = in_date
              window = in_window
          else:
              now = datetime.utcnow()
              start_hour = (now.hour // 6) * 6
              end_hour = start_hour + 6
              date = now.strftime('%Y-%m-%d')
              window = f"{start_hour:02d}-{end_hour:02d}"

          # Write to GITHUB_OUTPUT
          with open(os.environ['GITHUB_OUTPUT'], "a", encoding="utf-8") as fh:
              fh.write(f"date={date}\n")
              fh.write(f"window={window}\n")
          PY
      - name: Fetch headlines
        run: uv run jobs/fetch_headlines.py --country "${{ env.COUNTRY }}" --city "${{ env.CITY }}" --date "${{ steps.window.outputs.date }}" --window "${{ steps.window.outputs.window }}"

  classify-aggregate:
    runs-on: ubuntu-latest
    needs: fetch-headlines
    outputs:
      # Map step outputs to job outputs
      date: ${{ needs.fetch-headlines.outputs.date }}
      window: ${{ needs.fetch-headlines.outputs.window }}
    env:
      HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
      HOPSWORKS_PROJECT: ${{ secrets.HOPSWORKS_PROJECT || vars.HOPSWORKS_PROJECT }}
      HOPSWORKS_HOST: ${{ secrets.HOPSWORKS_HOST || vars.HOPSWORKS_HOST }}
      STORAGE_BACKEND: ${{ vars.STORAGE_BACKEND || 'local' }}
      STORAGE_BUCKET_NAME: ${{ vars.STORAGE_BUCKET_NAME || 'vibe-images' }}
      ASSETS_DIR: ${{ vars.ASSETS_DIR || './assets' }}
    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 1
          sparse-checkout: |
            backend
            .github
      - name: Set up uv
        uses: astral-sh/setup-uv@v7
        with:
          python-version: "3.13"
          enable-cache: true
      - name: Install dependencies
        run: uv sync --frozen
      - name: Classify headlines and aggregate vibe
        env:
          CLASSIFIER_ENDPOINT: ${{ env.CLASSIFIER_ENDPOINT }}
        run: |
          uv run jobs/classify_headlines.py \
            --city "${{ env.CITY }}" \
            --date "${{ needs.fetch-headlines.outputs.date }}" \
            --window "${{ needs.fetch-headlines.outputs.window }}" \
            --endpoint "$CLASSIFIER_ENDPOINT"

  generate-visualization:
    runs-on: ubuntu-latest
    needs: classify-aggregate
    env:
      HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
      HOPSWORKS_PROJECT: ${{ secrets.HOPSWORKS_PROJECT || vars.HOPSWORKS_PROJECT }}
      HOPSWORKS_HOST: ${{ secrets.HOPSWORKS_HOST || vars.HOPSWORKS_HOST }}
      ENABLE_POLISH: ${{ vars.ENABLE_POLISH || 'false' }}
      POLISH_PROVIDER: ${{ vars.POLISH_PROVIDER || 'mock' }}
      REPLICATE_MODEL_ID: ${{ vars.REPLICATE_MODEL_ID }}
      REPLICATE_API_TOKEN: ${{ secrets.REPLICATE_API_TOKEN }}
      STORAGE_BACKEND: ${{ vars.STORAGE_BACKEND || 'local' }}
      STORAGE_BUCKET_NAME: ${{ vars.STORAGE_BUCKET_NAME || 'vibe-images' }}
      ASSETS_DIR: ${{ vars.ASSETS_DIR || './assets' }}
    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 1
          sparse-checkout: |
            backend
            .github
      - name: Set up uv
        uses: astral-sh/setup-uv@v7
        with:
          python-version: "3.13"
          enable-cache: true
      - name: Install dependencies
        run: uv sync --frozen
      - name: Generate or fetch visualization
        run: |
          uv run jobs/generate_visualization.py \
            --city "${{ env.CITY }}" \
            --date "${{ needs.classify-aggregate.outputs.date }}" \
            --window "${{ needs.classify-aggregate.outputs.window }}"
